% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimizers.R
\name{adam}
\alias{adam}
\title{Adaptive Moment Estimation Optimizer}
\usage{
adam(
  X,
  y,
  w,
  m,
  max.steps,
  fx,
  pars,
  lr = 0.001,
  beta1 = 0.9,
  beta2 = 0.999,
  delta = 1e-05,
  ...
)
}
\arguments{
\item{X, y}{dataset and label.}

\item{w}{initial point.}

\item{m}{mini-batch size for pegasos solver.}

\item{max.steps}{the number of iterations to solve the optimization problem.}

\item{fx}{sub-gradient of objective function.}

\item{pars}{parameters list for the sub-gradient.}

\item{lr}{initial learning rate.}

\item{beta1}{first order moment parameter.}

\item{beta2}{second order moment parameter.}

\item{delta}{avoid division by 0.}

\item{...}{additional settings for the sub-gradient.}
}
\value{
return optimal solution.
}
\description{
Adaptive Moment Estimation Optimizer
}
\author{
Zhang Jiaqi.
}
